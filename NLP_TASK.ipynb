{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CLEANING AND PREPROCESSING TEXT DATA IN PANDAS FOR NLP TASK\n"
      ],
      "metadata": {
        "id": "_1JyL_g6YFaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning and preprocessing data is often one of the most daunting, yet critical phases in building AI and Machine Learning solutions fueled by data, and text data is not the exception.\n"
      ],
      "metadata": {
        "id": "aytEEty_Yjd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data into DataFrame\n"
      ],
      "metadata": {
        "id": "CE76LCsUbG5C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "g1Jc4bZ2Xv5D",
        "outputId": "e8f6f244-4eda-4fa7-de83-85f185b003a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         text\n",
              "0             I love cooking!\n",
              "1               Baking is fun\n",
              "2                        None\n",
              "3  Japanese cuisine is great!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbb06104-a607-4916-b15c-3e69b015db03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love cooking!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baking is fun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Japanese cuisine is great!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbb06104-a607-4916-b15c-3e69b015db03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbb06104-a607-4916-b15c-3e69b015db03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbb06104-a607-4916-b15c-3e69b015db03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b2fea38-03e3-476c-8d3c-768418ab813b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b2fea38-03e3-476c-8d3c-768418ab813b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b2fea38-03e3-476c-8d3c-768418ab813b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_df",
              "summary": "{\n  \"name\": \"data_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"I love cooking!\",\n          \"Baking is fun\",\n          \"Japanese cuisine is great!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "## Load the data into DataFrame\n",
        "import pandas as pd\n",
        "data = {'text': [\"I love cooking!\", \"Baking is fun\", None, \"Japanese cuisine is great!\"]}\n",
        "\n",
        "# Convert the data to a DataFrame\n",
        "data_df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Missing values\n"
      ],
      "metadata": {
        "id": "UZW8fNlFeDt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.dropna(subset = ['text'], inplace = True)\n",
        "print(data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BrkSOLied7Sv",
        "outputId": "85029362-3e2b-4611-bc8e-f69a66182158"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         text\n",
            "0             I love cooking!\n",
            "1               Baking is fun\n",
            "3  Japanese cuisine is great!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize the text to make it consitent\n",
        "- Normalizing text implies standardizing or unifying elements that may appear under different formats across different instances, for instance, date formats, full names, or case sensitiveness."
      ],
      "metadata": {
        "id": "QJ_CyiQDfJku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the data into lower cases\n",
        "data_df['text'] = data_df['text'].str.lower()\n",
        "print(data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m_q-nhraeiU9",
        "outputId": "d911e881-817a-42c9-ec37-775c0fb1bed6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         text\n",
            "0             i love cooking!\n",
            "1               baking is fun\n",
            "3  japanese cuisine is great!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To remove noise(Punctuation)\n",
        "- Noise is unnecessary or unexpectedly collected data that may hinder the subsequent modeling or prediction processes if not handled adequately."
      ],
      "metadata": {
        "id": "muQ28sB-fse3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "# print all the punctuation\n",
        "print(string.punctuation)\n",
        "\n",
        "# Create a translation table to remove all the punctuation\n",
        "translation_table = str.maketrans(\"\",\"\",string.punctuation)\n",
        "data_df['text'] = data_df['text'].str.translate(translation_table)\n",
        "print(data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tmWC1jwmfkUX",
        "outputId": "ed11aacc-bf29-464a-9b34-33f461294831"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "                        text\n",
            "0             i love cooking\n",
            "1              baking is fun\n",
            "3  japanese cuisine is great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize the text data\n",
        "- To slit the text into smaller units called tokens.\n",
        "- Tokenization is arguably the most important text preprocessing step -along with encoding text into a numerical representation- before using NLP and language models."
      ],
      "metadata": {
        "id": "gCLJ6F9-i99G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Vbbco_8Glrf3",
        "outputId": "aac7a870-3aca-48ea-9a8d-279526c9442e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Apply word_tokenize to each row in the 'text' column and store it in a new 'tokens' column\n",
        "data_df['tokens'] = data_df['text'].apply(word_tokenize)\n",
        "\n",
        "# Display the results\n",
        "print(data_df[['text', 'tokens']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CRHM3t1ogNGt",
        "outputId": "4ca50084-c7e8-47ef-f6f0-64461c5b9d1a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        text                          tokens\n",
            "0             i love cooking              [i, love, cooking]\n",
            "1              baking is fun               [baking, is, fun]\n",
            "3  japanese cuisine is great  [japanese, cuisine, is, great]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternate method for tokenization"
      ],
      "metadata": {
        "id": "R8kZgulytddj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['tokens'] = data_df['text'].str.split()\n",
        "print(data_df[['text','tokens']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hcnNqDRmkyQx",
        "outputId": "4e038995-f947-4f71-a0a7-a0507cd3d5fe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        text                          tokens\n",
            "0             i love cooking              [i, love, cooking]\n",
            "1              baking is fun               [baking, is, fun]\n",
            "3  japanese cuisine is great  [japanese, cuisine, is, great]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Stop words\n",
        "- Is removing words that don't add value while being the corpus.\n",
        "  - Document - This are individual text, string, observation.\n",
        "  - Corpus - Collection of ducuments"
      ],
      "metadata": {
        "id": "4PEmQHgqv54D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sJWWGvYewcd6",
        "outputId": "258796fb-0c6d-4884-ccc2-d487690f14a2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Initialize the stopwords function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Apply the stop_words to the tokens column\n",
        "data_df['tokens'] = data_df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# Display results\n",
        "print(data_df[['text', 'tokens']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "39Qb8DKSw8D0",
        "outputId": "85bcc827-3a99-4e26-f64a-c98249afd06f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        text                      tokens\n",
            "0             i love cooking             [love, cooking]\n",
            "1              baking is fun               [baking, fun]\n",
            "3  japanese cuisine is great  [japanese, cuisine, great]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming and Lemmatization\n",
        " - Stemming - is mapping words to their root word.\n",
        "  - SwonballStemmer\n",
        "  - PorterStemmer\n",
        "  - LancansterStemmer\n",
        " - lemmatization - is the morpholoical analysis of a word to reduce it to its base or Lemma\n",
        "  - WordNetLemmatizer"
      ],
      "metadata": {
        "id": "m8h8aAqQt5Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "s_Ony99TtVgg",
        "outputId": "85f3c1bd-99bb-4e27-bc4b-5b71aa05252c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iport necessary libraries\n",
        "from nltk import SnowballStemmer\n",
        "\n",
        "# Intialize SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "# Apply snollballstemmer to each row in the 'text' column and store it in a new 'stemmer' column\n",
        "data_df['stemmed'] = data_df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "\n",
        "# Print the results\n",
        "print(data_df[['tokens', 'stemmed']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fYQKJbrUu2cm",
        "outputId": "f6f3c216-b9a6-43e5-b4ac-804b83b3bfda"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       tokens                   stemmed\n",
            "0             [love, cooking]              [love, cook]\n",
            "1               [baking, fun]               [bake, fun]\n",
            "3  [japanese, cuisine, great]  [japanes, cuisin, great]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Text into Numerical Representations\n",
        " - we need to map our word vectors into numerical representations, commonly known as embedding vectors, or simply embedding.\n",
        "\n",
        " The below example converts tokenized text in the 'tokens' column and uses a TF-IDF vectorization approach (one of the most popular approaches in the good old days of classical NLP) to transform the text into numerical representations."
      ],
      "metadata": {
        "id": "YpknMYtW17lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Join text and tokens\n",
        "data_df['text'] = data_df['tokens'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Implement the TfidfVectorizer\n",
        "X = vectorizer.fit_transform(data_df['text'])\n",
        "\n",
        "# Display and convert X to an array\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I9T_ZJAdvTsq",
        "outputId": "3a312bcf-6fd5-468a-a06d-d930ba05ca41"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.70710678 0.         0.         0.         0.\n",
            "  0.70710678]\n",
            " [0.70710678 0.         0.         0.70710678 0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.57735027 0.         0.57735027 0.57735027\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step would be feeding these numerical representations to our NLP model to let it do its magic"
      ],
      "metadata": {
        "id": "IDiX9RDY37ou"
      }
    }
  ]
}